import sys
import pyaudio
import wave
import numpy as np
import threading
import queue
import requests
import time
import os
import json
import whisper
import tempfile
from collections import deque
from pynput import keyboard
from PyQt5.QtWidgets import (QApplication, QMainWindow, QVBoxLayout, QHBoxLayout,
                             QWidget, QLabel, QPushButton, QColorDialog,
                             QFontDialog, QGroupBox, QComboBox, QMessageBox,
                             QSlider, QMenu, QDialog, QCheckBox, QTextEdit, QLineEdit, QInputDialog)
from PyQt5.QtCore import Qt, pyqtSignal, QThread, QTimer
from PyQt5.QtGui import QFont, QColor, QPalette, QCursor


class WhisperSpeechRecognizer(QThread):
    """Whisperè¯­éŸ³è¯†åˆ«çº¿ç¨‹ - è‡ªåŠ¨è¯­è¨€æ£€æµ‹"""
    text_recognized = pyqtSignal(str, str)  # æ–‡æœ¬, æ£€æµ‹åˆ°çš„è¯­è¨€
    status_updated = pyqtSignal(str)  # çŠ¶æ€æ›´æ–°
    volume_updated = pyqtSignal(int)  # éŸ³é‡æ›´æ–°

    def __init__(self, device_index=1, model_size="base"):
        super().__init__()
        self.device_index = device_index
        self.model_size = model_size
        self._is_running = True

        # éŸ³é¢‘å‚æ•° - è°ƒæ•´å‚æ•°æé«˜çµæ•åº¦
        self.chunk_size = 1024
        self.sample_format = pyaudio.paInt16
        self.channels = 1
        self.sample_rate = 16000
        self.silence_threshold = 100  # é™ä½é˜ˆå€¼ï¼Œæ›´å®¹æ˜“è§¦å‘

        # å½•éŸ³å‚æ•° - è°ƒæ•´æ–­å¥é€»è¾‘
        self.audio_buffer = []
        self.silence_frames = 0
        self.is_speaking = False
        self.silence_duration_threshold = 1.2  # 1.2ç§’é™éŸ³æ–­å¥
        self.min_speech_duration = 0.5  # é™ä½æœ€å°æ—¶é•¿
        self.max_speech_duration = 8.0

        # è°ƒè¯•è®¡æ•°å™¨
        self.debug_counter = 0

        # Whisperæ¨¡å‹
        print(f"ğŸ”„ åŠ è½½Whisperæ¨¡å‹: {model_size}")
        self.model = whisper.load_model(model_size)
        print("âœ… Whisperæ¨¡å‹åŠ è½½å®Œæˆ")

        # éŸ³é¢‘é˜Ÿåˆ—
        self.audio_queue = queue.Queue()

    def audio_callback(self, in_data, frame_count, time_info, status):
        """éŸ³é¢‘è¾“å…¥å›è°ƒ"""
        if self._is_running:
            self.audio_queue.put(in_data)
        return (in_data, pyaudio.paContinue)

    def run(self):
        """ä¸»è¯†åˆ«å¾ªç¯"""
        print("ğŸ¤ Whisperè¯­éŸ³è¯†åˆ«å¯åŠ¨ - è‡ªåŠ¨è¯­è¨€æ£€æµ‹")
        self.status_updated.emit("çŠ¶æ€: Whisperè¯†åˆ«å¯åŠ¨")

        if not self._setup_audio_stream():
            return

        self.status_updated.emit("çŠ¶æ€: ğŸ¤ ç›‘å¬ä¸­...")
        print("ğŸ”Š å¼€å§‹éŸ³é¢‘å¤„ç†å¾ªç¯...")
        self._process_audio_stream()

    def _setup_audio_stream(self):
        """è®¾ç½®éŸ³é¢‘æµ"""
        try:
            self.audio = pyaudio.PyAudio()
            device_info = self.audio.get_device_info_by_index(self.device_index)
            print(f"ğŸ§ ä½¿ç”¨éŸ³é¢‘è®¾å¤‡: {device_info['name']}")

            self.stream = self.audio.open(
                format=self.sample_format,
                channels=self.channels,
                rate=self.sample_rate,
                frames_per_buffer=self.chunk_size,
                input=True,
                input_device_index=self.device_index,
                stream_callback=self.audio_callback
            )
            self.stream.start_stream()
            print("âœ… éŸ³é¢‘æµå¯åŠ¨æˆåŠŸ")
            print(f"ğŸ“Š é™éŸ³é˜ˆå€¼: {self.silence_threshold}")
            return True

        except Exception as e:
            print(f"âŒ éŸ³é¢‘æµè®¾ç½®å¤±è´¥: {e}")
            self.status_updated.emit(f"çŠ¶æ€: éŸ³é¢‘é”™è¯¯ - {str(e)}")
            return False

    def _process_audio_stream(self):
        """å¤„ç†éŸ³é¢‘æµæ•°æ®"""
        print("ğŸ¯ å¼€å§‹è¯­éŸ³æ£€æµ‹...")

        while self._is_running:
            try:
                # è·å–éŸ³é¢‘æ•°æ®
                data = self.audio_queue.get(timeout=0.1)
                if not data:
                    continue

                audio_data = np.frombuffer(data, dtype=np.int16)

                # è®¡ç®—éŸ³é‡
                if len(audio_data) > 0:
                    volume = np.mean(np.abs(audio_data))
                    if np.isnan(volume) or np.isinf(volume):
                        volume = 0
                else:
                    volume = 0

                self.volume_updated.emit(int(volume))

                # è°ƒè¯•è¾“å‡ºï¼ˆæ¯50æ¬¡è¾“å‡ºä¸€æ¬¡ï¼‰
                self.debug_counter += 1
                if self.debug_counter % 50 == 0:
                    speaking_status = "è¯´è¯ä¸­" if self.is_speaking else "é™éŸ³"
                    print(f"ğŸ“Š éŸ³é‡: {volume:.1f}, çŠ¶æ€: {speaking_status}, ç¼“å†²åŒº: {len(self.audio_buffer)}å¸§")

                # è¯­éŸ³æ´»åŠ¨æ£€æµ‹
                if volume > self.silence_threshold:
                    self.silence_frames = 0
                    if not self.is_speaking:
                        # å¼€å§‹è¯´è¯
                        self.is_speaking = True
                        self.audio_buffer = [data]
                        print(f"ğŸ¤ æ£€æµ‹åˆ°è¯­éŸ³å¼€å§‹ï¼éŸ³é‡: {volume:.1f}")
                        self.status_updated.emit("çŠ¶æ€: ğŸ¤ æ£€æµ‹åˆ°è¯­éŸ³")
                    else:
                        # æŒç»­è¯´è¯
                        self.audio_buffer.append(data)
                else:
                    # é™éŸ³
                    self.silence_frames += 1
                    if self.is_speaking:
                        self.audio_buffer.append(data)  # é™éŸ³å¸§ä¹Ÿæ”¶é›†

                # è®¡ç®—éŸ³é¢‘æ—¶é•¿
                if self.audio_buffer:
                    audio_duration = len(self.audio_buffer) * self.chunk_size / self.sample_rate
                else:
                    audio_duration = 0

                # æ–­å¥æ¡ä»¶
                should_process = False
                reason = ""

                if self.is_speaking:
                    silence_duration = self.silence_frames * self.chunk_size / self.sample_rate

                    # æ¡ä»¶1: é™éŸ³æ–­å¥
                    if (silence_duration >= self.silence_duration_threshold and
                            audio_duration >= self.min_speech_duration):
                        should_process = True
                        reason = f"é™éŸ³æ–­å¥ ({silence_duration:.1f}ç§’é™éŸ³)"

                    # æ¡ä»¶2: è¶…é•¿æ–­å¥
                    elif audio_duration >= self.max_speech_duration:
                        should_process = True
                        reason = f"è¶…é•¿æ–­å¥ ({audio_duration:.1f}ç§’)"

                    # æ¡ä»¶3: çŸ­å¥å¿«é€Ÿå¤„ç†
                    elif (audio_duration >= 1.0 and
                          silence_duration >= 0.8 and
                          volume < self.silence_threshold * 0.7):
                        should_process = True
                        reason = f"çŸ­å¥æ–­å¥ ({audio_duration:.1f}ç§’)"

                # å¤„ç†è¯­éŸ³æ®µ
                if should_process and self.audio_buffer:
                    print(f"ğŸ¯ {reason}, éŸ³é¢‘æ—¶é•¿: {audio_duration:.1f}ç§’")
                    audio_data = b''.join(self.audio_buffer)
                    self._process_speech(audio_data)

                    # é‡ç½®çŠ¶æ€ï¼Œä¿ç•™å°‘é‡ä¸Šä¸‹æ–‡
                    keep_frames = int(0.3 * self.sample_rate / self.chunk_size)
                    if len(self.audio_buffer) > keep_frames:
                        self.audio_buffer = self.audio_buffer[-keep_frames:]
                    else:
                        self.audio_buffer = []

                    self.is_speaking = False
                    self.silence_frames = 0
                    print("ğŸ”„ é‡ç½®è¯­éŸ³æ£€æµ‹çŠ¶æ€")

            except queue.Empty:
                # å¤„ç†é™éŸ³è¶…æ—¶
                if self.is_speaking and self.audio_buffer:
                    audio_duration = len(self.audio_buffer) * self.chunk_size / self.sample_rate
                    if audio_duration >= self.min_speech_duration:
                        print(f"â° é˜Ÿåˆ—è¶…æ—¶ï¼Œå¤„ç†éŸ³é¢‘: {audio_duration:.1f}ç§’")
                        audio_data = b''.join(self.audio_buffer)
                        self._process_speech(audio_data)
                        self.audio_buffer = []
                        self.is_speaking = False
                continue

            except Exception as e:
                print(f"éŸ³é¢‘å¤„ç†é”™è¯¯: {e}")
                continue

        self._cleanup()

    def _process_speech(self, audio_data):
        """å¤„ç†è¯­éŸ³è¯†åˆ«"""
        try:
            # ä¿å­˜ä¸´æ—¶éŸ³é¢‘æ–‡ä»¶
            with tempfile.NamedTemporaryFile(suffix=".wav", delete=False) as temp_file:
                temp_path = temp_file.name

            # ä¿å­˜ä¸ºWAVæ–‡ä»¶
            with wave.open(temp_path, 'wb') as wf:
                wf.setnchannels(self.channels)
                wf.setsampwidth(2)
                wf.setframerate(self.sample_rate)
                wf.writeframes(audio_data)

            print("ğŸ” Whisperè¯†åˆ«ä¸­...")
            self.status_updated.emit("çŠ¶æ€: ğŸ” è¯†åˆ«ä¸­...")

            # ä½¿ç”¨Whisperè¯†åˆ«ï¼ˆè‡ªåŠ¨æ£€æµ‹è¯­è¨€ï¼‰
            result = self.model.transcribe(
                temp_path,
                fp16=False,  # ä½¿ç”¨FP32æé«˜ç²¾åº¦
                language=None  # è‡ªåŠ¨æ£€æµ‹è¯­è¨€
            )

            text = result["text"].strip()
            detected_language = result.get("language", "unknown")

            # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
            try:
                os.unlink(temp_path)
            except:
                pass

            if text and len(text) > 1:
                language_name = self._get_language_name(detected_language)
                print(f"âœ… Whisperè¯†åˆ«: [{language_name}] {text}")
                self.text_recognized.emit(text, detected_language)
                self.status_updated.emit(f"çŠ¶æ€: âœ… è¯†åˆ«å®Œæˆ ({language_name})")
            else:
                print("âŒ è¯†åˆ«å¤±è´¥: æ— æœ‰æ•ˆæ–‡æœ¬")
                self.status_updated.emit("çŠ¶æ€: âŒ è¯†åˆ«å¤±è´¥")

        except Exception as e:
            print(f"è¯­éŸ³è¯†åˆ«é”™è¯¯: {e}")
            self.status_updated.emit("çŠ¶æ€: âŒ è¯†åˆ«é”™è¯¯")

    def _get_language_name(self, lang_code):
        """è·å–è¯­è¨€åç§°"""
        language_names = {
            "en": "è‹±æ–‡",
            "zh": "ä¸­æ–‡",
            "ja": "æ—¥æ–‡",
            "ko": "éŸ©æ–‡",
            "fr": "æ³•æ–‡",
            "de": "å¾·æ–‡",
            "es": "è¥¿ç­ç‰™æ–‡",
            "ru": "ä¿„æ–‡"
        }
        return language_names.get(lang_code, lang_code)

    def stop(self):
        """åœæ­¢è¯†åˆ«"""
        self._is_running = False

    def _cleanup(self):
        """æ¸…ç†èµ„æº"""
        if hasattr(self, 'stream') and self.stream:
            try:
                self.stream.stop_stream()
                self.stream.close()
            except:
                pass
        if hasattr(self, 'audio') and self.audio:
            try:
                self.audio.terminate()
            except:
                pass
        print("ğŸ›‘ Whisperè¯†åˆ«çº¿ç¨‹é€€å‡º")


class TranslationWorker(QThread):
    """ç¿»è¯‘å·¥ä½œçº¿ç¨‹"""
    translation_finished = pyqtSignal(str, str, str)  # original, translation, source_lang
    translation_failed = pyqtSignal(str, str)  # original, error

    def __init__(self, model_name="qwen2.5:3b"):
        super().__init__()
        self.model_name = model_name
        self.ollama_url = "http://localhost:11434/api/generate"
        self.request_queue = queue.Queue()
        self._is_running = True

    def add_translation_task(self, text, source_language):
        """æ·»åŠ ç¿»è¯‘ä»»åŠ¡"""
        if text and text.strip():
            self.request_queue.put((text, source_language))
            print(f"ğŸ“¨ æ·»åŠ ç¿»è¯‘ä»»åŠ¡: [{source_language}] {text}")

    def run(self):
        """ç¿»è¯‘å¤„ç†å¾ªç¯"""
        print("ğŸŒ ç¿»è¯‘çº¿ç¨‹å¯åŠ¨")
        while self._is_running:
            try:
                task = self.request_queue.get(timeout=1.0)
                if task:
                    text, source_language = task
                    self._process_translation(text, source_language)
            except queue.Empty:
                continue
            except Exception as e:
                print(f"ç¿»è¯‘çº¿ç¨‹é”™è¯¯: {e}")

    def _process_translation(self, text, source_language):
        """å¤„ç†å•ä¸ªç¿»è¯‘ä»»åŠ¡"""
        print(f"ğŸ”„ å¼€å§‹ç¿»è¯‘: [{source_language}] {text}")

        try:
            # æ ¹æ®æ£€æµ‹åˆ°çš„è¯­è¨€å†³å®šç¿»è¯‘æ–¹å‘
            if source_language == "zh":  # ä¸­æ–‡ -> è‹±æ–‡
                prompt = f"Translate this Chinese to English: {text}"
            else:  # å…¶ä»–è¯­è¨€ï¼ˆä¸»è¦æ˜¯è‹±æ–‡ï¼‰-> ä¸­æ–‡
                prompt = f"Translate this to Chinese: {text}"

            payload = {
                "model": self.model_name,
                "prompt": prompt,
                "stream": False
            }

            # å‘é€ç¿»è¯‘è¯·æ±‚
            start_time = time.time()
            response = requests.post(self.ollama_url, json=payload, timeout=30)
            response_time = (time.time() - start_time) * 1000

            if response.status_code == 200:
                result = response.json()
                translation = result.get("response", "").strip()
                translation = self._clean_translation(translation)

                print(f"âœ… ç¿»è¯‘å®Œæˆ ({response_time:.0f}ms): {translation}")
                self.translation_finished.emit(text, translation, source_language)
            else:
                error_msg = f"HTTPé”™è¯¯: {response.status_code}"
                print(f"âŒ {error_msg}")
                self.translation_failed.emit(text, error_msg)

        except requests.exceptions.Timeout:
            error_msg = "ç¿»è¯‘è¶…æ—¶"
            print(f"âŒ {error_msg}")
            self.translation_failed.emit(text, error_msg)
        except requests.exceptions.ConnectionError:
            error_msg = "è¿æ¥Ollamaå¤±è´¥"
            print(f"âŒ {error_msg}")
            self.translation_failed.emit(text, error_msg)
        except Exception as e:
            error_msg = f"ç¿»è¯‘å¼‚å¸¸: {str(e)}"
            print(f"âŒ {error_msg}")
            self.translation_failed.emit(text, error_msg)

    def _clean_translation(self, translation):
        """æ¸…ç†ç¿»è¯‘ç»“æœ"""
        remove_prefixes = [
            "ä»¥ä¸‹è‹±æ–‡ç¿»è¯‘æˆä¸­æ–‡ï¼š", "ä»¥ä¸‹ä¸­æ–‡ç¿»è¯‘æˆè‹±æ–‡ï¼š",
            "ç¿»è¯‘ï¼š", "Translation:", ":", "ï¼š",
            "Translate this English to Chinese:", "Translate this Chinese to English:",
            "Translate to Chinese:", "Translate to English:",
            "ä¸­æ–‡ç¿»è¯‘ï¼š", "è‹±æ–‡ç¿»è¯‘ï¼š",
            "Here is the translation:", "The translation is:",
            "å¥½çš„ï¼Œ", "Okay,", "å—¯ï¼Œ", "Certainly,"
        ]

        # ç§»é™¤å‰ç¼€
        for prefix in remove_prefixes:
            if translation.startswith(prefix):
                translation = translation[len(prefix):].strip()

        return translation.strip()

    def stop(self):
        """åœæ­¢ç¿»è¯‘çº¿ç¨‹"""
        self._is_running = False


class DraggableSubtitleWindow(QMainWindow):
    def __init__(self):
        super().__init__()
        # åˆå§‹åŒ–å˜é‡
        self.model_name = "qwen2.5:3b"
        self.is_recording = False
        self.audio_device_index = 1
        self.hide_ui = False
        self.text_opacity = 255
        self.background_opacity = 180
        self.whisper_model_size = "base"  # base, small, medium

        # æ¨¡å‹åˆ—è¡¨
        self.custom_models = ["qwen2.5:3b", "deepseek-r1:7b"]

        # å·¥ä½œçº¿ç¨‹
        self.speech_recognizer = None
        self.translation_worker = None

        # å­—å¹•æ•°æ®
        self.previous_subtitle = {"original": "", "translation": "", "language": ""}
        self.current_subtitle = {"original": "", "translation": "", "language": ""}

        # UIè®¾ç½®
        self.font_size = 18
        self.bg_color = QColor(0, 0, 0, self.background_opacity)
        self.original_color = QColor(255, 255, 0, self.text_opacity)
        self.translation_color = QColor(0, 255, 255, self.text_opacity)

        # åˆå§‹åŒ–UI
        self.central_widget = QWidget()
        self.setCentralWidget(self.central_widget)
        self.init_ui()
        self.setup_keyboard_listener()

        # å¯åŠ¨ç¿»è¯‘çº¿ç¨‹
        self._start_translation_worker()

    def _start_translation_worker(self):
        """å¯åŠ¨ç¿»è¯‘å·¥ä½œçº¿ç¨‹"""
        self.translation_worker = TranslationWorker(self.model_name)
        self.translation_worker.translation_finished.connect(self.on_translation_finished)
        self.translation_worker.translation_failed.connect(self.on_translation_failed)
        self.translation_worker.start()
        print("âœ… ç¿»è¯‘çº¿ç¨‹å¯åŠ¨")

    def init_ui(self):
        """åˆå§‹åŒ–UIç•Œé¢"""
        self.setWindowTitle("å®æ—¶åŒè¯­å­—å¹• - Whisperæ™ºèƒ½ç‰ˆ")
        self.setGeometry(100, 100, 1000, 300)
        self.setWindowFlags(Qt.FramelessWindowHint | Qt.WindowStaysOnTopHint | Qt.Tool)
        self.setAttribute(Qt.WA_TranslucentBackground)

        # è®¾ç½®æ ·å¼
        self.central_widget.setStyleSheet(
            f"background-color: rgba({self.bg_color.red()}, {self.bg_color.green()}, {self.bg_color.blue()}, {self.background_opacity}); border-radius: 10px;")

        layout = QVBoxLayout(self.central_widget)
        layout.setSpacing(5)
        layout.setContentsMargins(15, 15, 15, 15)

        # æ ‡é¢˜æ 
        self.title_bar = QWidget()
        self.title_bar.setFixedHeight(25)
        self.title_bar.setStyleSheet("background-color: rgba(50, 50, 50, 200); border-radius: 5px;")
        title_layout = QHBoxLayout(self.title_bar)
        title_layout.setContentsMargins(10, 0, 10, 0)

        title_label = QLabel("ğŸ¯ å®æ—¶åŒè¯­å­—å¹• - Whisperæ™ºèƒ½è¯†åˆ« â€¢ æ‹–åŠ¨ç§»åŠ¨ â€¢ å³é”®èœå•")
        title_label.setStyleSheet("color: white; font-size: 12px;")
        title_layout.addWidget(title_label)
        title_layout.addStretch()

        # æœ€å°åŒ–å’Œå…³é—­æŒ‰é’®
        self.min_btn = QPushButton("â€”")
        self.min_btn.setFixedSize(20, 20)
        self.min_btn.setStyleSheet(
            "QPushButton{background-color: #555; color: white; border: none; border-radius: 3px;} QPushButton:hover{background-color: #666;}")
        self.min_btn.clicked.connect(self.showMinimized)
        title_layout.addWidget(self.min_btn)

        self.close_btn = QPushButton("Ã—")
        self.close_btn.setFixedSize(20, 20)
        self.close_btn.setStyleSheet(
            "QPushButton{background-color: #d00; color: white; border: none; border-radius: 3px;} QPushButton:hover{background-color: #f00;}")
        self.close_btn.clicked.connect(self.close)
        title_layout.addWidget(self.close_btn)

        # å­—å¹•æ˜¾ç¤ºåŒºåŸŸ
        self.previous_original_label = QLabel("")
        self.previous_original_label.setAlignment(Qt.AlignCenter)
        self.previous_original_label.setWordWrap(True)

        self.previous_translation_label = QLabel("")
        self.previous_translation_label.setAlignment(Qt.AlignCenter)
        self.previous_translation_label.setWordWrap(True)

        self.separator = QWidget()
        self.separator.setFixedHeight(1)
        self.separator.setStyleSheet("background-color: rgba(255, 255, 255, 100);")

        self.current_original_label = QLabel("å‡†å¤‡å°±ç»ª - æŒ‰F2å¼€å§‹ç¿»è¯‘")
        self.current_original_label.setAlignment(Qt.AlignCenter)
        self.current_original_label.setWordWrap(True)

        self.current_translation_label = QLabel("Ready - Press F2 to start")
        self.current_translation_label.setAlignment(Qt.AlignCenter)
        self.current_translation_label.setWordWrap(True)

        # è¯­è¨€æ˜¾ç¤ºæ ‡ç­¾
        self.language_label = QLabel("")
        self.language_label.setAlignment(Qt.AlignCenter)
        self.language_label.setStyleSheet(
            "color: #FFA500; background-color: rgba(50, 50, 50, 200); padding: 2px; border-radius: 3px;")

        # æ§åˆ¶é¢æ¿
        self.control_group = QGroupBox()
        self.control_group.setStyleSheet(
            "QGroupBox{color: white; border: 1px solid rgba(255,255,255,100); border-radius: 5px; margin-top: 10px;} QGroupBox::title{subcontrol-origin: margin; left: 10px; padding: 0 5px 0 5px;}")
        control_layout = QHBoxLayout()

        self.start_btn = QPushButton("å¼€å§‹ç¿»è¯‘ (F2)")
        self.start_btn.clicked.connect(self.toggle_recording)
        self.start_btn.setStyleSheet(
            "QPushButton{background-color: rgba(0, 100, 0, 200); color: white; border: none; padding: 8px 15px; border-radius: 3px;} QPushButton:hover{background-color: rgba(0, 150, 0, 200);}")

        self.settings_btn = QPushButton("éŸ³é¢‘è®¾å¤‡")
        self.settings_btn.clicked.connect(self.show_device_dialog)
        self.settings_btn.setStyleSheet(
            "QPushButton{background-color: rgba(100, 100, 100, 200); color: white; border: none; padding: 8px 15px; border-radius: 3px;} QPushButton:hover{background-color: rgba(150, 150, 150, 200);}")

        control_layout.addWidget(self.start_btn)
        control_layout.addWidget(self.settings_btn)
        control_layout.addStretch()
        self.control_group.setLayout(control_layout)

        # çŠ¶æ€æ˜¾ç¤º
        self.status_label = QLabel("çŠ¶æ€: ç­‰å¾…å¼€å§‹")
        self.status_label.setAlignment(Qt.AlignCenter)
        self.status_label.setStyleSheet(
            "color: white; background-color: rgba(50, 50, 50, 200); padding: 3px; border-radius: 3px;")

        # éŸ³é‡æ˜¾ç¤º
        self.volume_label = QLabel("éŸ³é‡: 0")
        self.volume_label.setAlignment(Qt.AlignCenter)
        self.volume_label.setStyleSheet(
            "color: lime; background-color: rgba(0, 50, 0, 200); padding: 2px; border-radius: 3px;")

        # æ·»åŠ åˆ°å¸ƒå±€
        layout.addWidget(self.title_bar)
        layout.addWidget(self.previous_original_label)
        layout.addWidget(self.previous_translation_label)
        layout.addWidget(self.separator)
        layout.addWidget(self.current_original_label)
        layout.addWidget(self.current_translation_label)
        layout.addWidget(self.language_label)
        layout.addStretch()
        layout.addWidget(self.control_group)
        layout.addWidget(self.volume_label)
        layout.addWidget(self.status_label)

        self.apply_fonts()
        self.update_text_style()

    def on_speech_recognized(self, text, detected_language):
        """å¤„ç†è¯†åˆ«åˆ°çš„è¯­éŸ³æ–‡æœ¬"""
        print(f"ğŸ¯ æ”¶åˆ°è¯†åˆ«æ–‡æœ¬: [{detected_language}] {text}")

        # æ›´æ–°è¯­è¨€æ˜¾ç¤º
        language_name = self._get_language_name(detected_language)
        self.language_label.setText(f"æ£€æµ‹è¯­è¨€: {language_name}")

        # ç¬¬ä¸€æ­¥ï¼šç«‹å³æ›´æ–°ç•Œé¢æ˜¾ç¤ºè¯†åˆ«çš„æ–‡æœ¬
        if self.current_subtitle["original"]:
            self.previous_subtitle = self.current_subtitle.copy()

        self.current_subtitle = {
            "original": text,
            "translation": "ğŸ”„ ç¿»è¯‘ä¸­...",
            "language": detected_language
        }
        self.update_display()

        # ç¬¬äºŒæ­¥ï¼šå‘é€ç¿»è¯‘ä»»åŠ¡ï¼ˆåŒ…å«æºè¯­è¨€ä¿¡æ¯ï¼‰
        if self.translation_worker:
            self.translation_worker.add_translation_task(text, detected_language)

    def on_translation_finished(self, original_text, translated_text, source_language):
        """ç¿»è¯‘å®Œæˆå›è°ƒ"""
        if self.current_subtitle["original"] == original_text:
            self.current_subtitle["translation"] = translated_text
            self.update_display()
            print(f"âœ… ç¿»è¯‘ç»“æœæ˜¾ç¤ºå®Œæˆ: {translated_text}")

    def on_translation_failed(self, original_text, error_msg):
        """ç¿»è¯‘å¤±è´¥å›è°ƒ"""
        if self.current_subtitle["original"] == original_text:
            self.current_subtitle["translation"] = f"âŒ ç¿»è¯‘å¤±è´¥"
            self.update_display()
            print(f"âŒ ç¿»è¯‘å¤±è´¥: {error_msg}")

    def _get_language_name(self, lang_code):
        """è·å–è¯­è¨€åç§°"""
        language_names = {
            "en": "English",
            "zh": "ä¸­æ–‡",
            "ja": "Japanese",
            "ko": "Korean",
            "fr": "French",
            "de": "German",
            "es": "Spanish",
            "ru": "Russian",
            "unknown": "æœªçŸ¥"
        }
        return language_names.get(lang_code, lang_code)

    def toggle_recording(self):
        """åˆ‡æ¢å½•éŸ³çŠ¶æ€"""
        if not self.is_recording:
            self.start_recording()
        else:
            self.stop_recording()

    def start_recording(self):
        """å¼€å§‹è¯­éŸ³è¯†åˆ«"""
        # æ£€æŸ¥OllamaæœåŠ¡
        if not self.check_ollama_availability():
            QMessageBox.warning(self, "è­¦å‘Š", "æ— æ³•è¿æ¥åˆ°OllamaæœåŠ¡ï¼Œè¯·ç¡®ä¿Ollamaæ­£åœ¨è¿è¡Œï¼")
            return

        self.is_recording = True
        self.start_btn.setText("åœæ­¢ç¿»è¯‘ (F2)")
        self.start_btn.setStyleSheet(
            "QPushButton{background-color: rgba(200, 0, 0, 200); color: white; border: none; padding: 8px 15px; border-radius: 3px;} QPushButton:hover{background-color: rgba(255, 0, 0, 200);}")
        self.status_label.setText("çŠ¶æ€: å¯åŠ¨Whisperè¯†åˆ«...")

        # å¯åŠ¨Whisperè¯­éŸ³è¯†åˆ«çº¿ç¨‹
        self.speech_recognizer = WhisperSpeechRecognizer(
            device_index=self.audio_device_index,
            model_size=self.whisper_model_size
        )
        self.speech_recognizer.text_recognized.connect(self.on_speech_recognized)
        self.speech_recognizer.status_updated.connect(self.status_label.setText)
        self.speech_recognizer.volume_updated.connect(self.on_volume_updated)
        self.speech_recognizer.start()

        print("ğŸ¤ å¼€å§‹Whisperæ™ºèƒ½è¯­éŸ³è¯†åˆ«")

    def stop_recording(self):
        """åœæ­¢è¯­éŸ³è¯†åˆ«"""
        self.is_recording = False
        self.start_btn.setText("å¼€å§‹ç¿»è¯‘ (F2)")
        self.start_btn.setStyleSheet(
            "QPushButton{background-color: rgba(0, 100, 0, 200); color: white; border: none; padding: 8px 15px; border-radius: 3px;} QPushButton:hover{background-color: rgba(0, 150, 0, 200);}")
        self.status_label.setText("çŠ¶æ€: å·²åœæ­¢")
        self.volume_label.setText("éŸ³é‡: 0")
        self.language_label.setText("")

        # åœæ­¢è¯­éŸ³è¯†åˆ«
        if self.speech_recognizer:
            self.speech_recognizer.stop()
            self.speech_recognizer.wait(3000)

        print("ğŸ›‘ è¯­éŸ³è¯†åˆ«åœæ­¢")

    def on_volume_updated(self, volume):
        """æ›´æ–°éŸ³é‡æ˜¾ç¤º"""
        self.volume_label.setText(f"éŸ³é‡: {volume}")

    def check_ollama_availability(self):
        """æ£€æŸ¥OllamaæœåŠ¡æ˜¯å¦å¯ç”¨"""
        try:
            response = requests.get("http://localhost:11434/api/tags", timeout=5)
            if response.status_code == 200:
                print("âœ… OllamaæœåŠ¡è¿æ¥æˆåŠŸ")
                return True
            else:
                print("âŒ æ— æ³•è¿æ¥åˆ°OllamaæœåŠ¡")
                return False
        except Exception as e:
            print(f"âŒ Ollamaè¿æ¥å¤±è´¥: {e}")
            return False

    def update_display(self):
        """æ›´æ–°ç•Œé¢æ˜¾ç¤º"""
        self.previous_original_label.setText(self.previous_subtitle["original"])
        self.previous_translation_label.setText(self.previous_subtitle["translation"])
        self.current_original_label.setText(self.current_subtitle["original"])
        self.current_translation_label.setText(self.current_subtitle["translation"])

    def show_device_dialog(self):
        """æ˜¾ç¤ºéŸ³é¢‘è®¾å¤‡è®¾ç½®å¯¹è¯æ¡†"""
        dialog = QDialog(self)
        dialog.setWindowTitle("éŸ³é¢‘è®¾å¤‡è®¾ç½®")
        dialog.setFixedSize(400, 200)
        layout = QVBoxLayout()

        layout.addWidget(QLabel("é€‰æ‹©éŸ³é¢‘è¾“å…¥è®¾å¤‡:"))

        device_combo = QComboBox()
        try:
            audio = pyaudio.PyAudio()
            for i in range(audio.get_device_count()):
                device_info = audio.get_device_info_by_index(i)
                if device_info['maxInputChannels'] > 0:
                    device_name = device_info['name']
                    device_combo.addItem(f"{i}: {device_name}", i)
            audio.terminate()
        except Exception as e:
            print(f"è·å–éŸ³é¢‘è®¾å¤‡å¤±è´¥: {e}")

        # é€‰æ‹©ç«‹ä½“å£°æ··éŸ³è®¾å¤‡
        for i in range(device_combo.count()):
            if "stereo" in device_combo.itemText(i).lower() or "æ··éŸ³" in device_combo.itemText(i):
                device_combo.setCurrentIndex(i)
                self.audio_device_index = device_combo.itemData(i)
                break

        layout.addWidget(device_combo)

        btn_layout = QHBoxLayout()
        ok_btn = QPushButton("ç¡®å®š")
        ok_btn.clicked.connect(lambda: self.on_device_selected(device_combo.currentData(), dialog))
        cancel_btn = QPushButton("å–æ¶ˆ")
        cancel_btn.clicked.connect(dialog.reject)
        btn_layout.addWidget(ok_btn)
        btn_layout.addWidget(cancel_btn)

        layout.addLayout(btn_layout)
        dialog.setLayout(layout)
        dialog.exec_()

    def on_device_selected(self, device_index, dialog):
        """è®¾å¤‡é€‰æ‹©ç¡®è®¤"""
        self.audio_device_index = device_index
        print(f"é€‰æ‹©éŸ³é¢‘è®¾å¤‡: {device_index}")
        dialog.accept()

    def set_whisper_model(self, model_size):
        """è®¾ç½®Whisperæ¨¡å‹å¤§å°"""
        self.whisper_model_size = model_size
        print(f"åˆ‡æ¢Whisperæ¨¡å‹: {model_size}")

    def update_background_style(self):
        """æ›´æ–°èƒŒæ™¯æ ·å¼"""
        self.central_widget.setStyleSheet(
            f"background-color: rgba({self.bg_color.red()}, {self.bg_color.green()}, {self.bg_color.blue()}, {self.background_opacity}); border-radius: 10px;")

    def update_text_style(self):
        """æ›´æ–°æ–‡å­—æ ·å¼"""
        original_style = f"color: rgba({self.original_color.red()}, {self.original_color.green()}, {self.original_color.blue()}, {self.text_opacity}); background-color: transparent;"
        translation_style = f"color: rgba({self.translation_color.red()}, {self.translation_color.green()}, {self.translation_color.blue()}, {self.text_opacity}); background-color: transparent;"

        self.current_original_label.setStyleSheet(original_style)
        self.previous_original_label.setStyleSheet(original_style)
        self.current_translation_label.setStyleSheet(translation_style)
        self.previous_translation_label.setStyleSheet(translation_style)

    def apply_fonts(self):
        """åº”ç”¨å­—ä½“è®¾ç½®"""
        previous_font = QFont("Microsoft YaHei", self.font_size - 3)
        current_font = QFont("Microsoft YaHei", self.font_size, QFont.Bold)

        self.previous_original_label.setFont(previous_font)
        self.previous_translation_label.setFont(previous_font)
        self.current_original_label.setFont(current_font)
        self.current_translation_label.setFont(QFont("Microsoft YaHei", self.font_size))

    def toggle_ui_visibility(self):
        """åˆ‡æ¢UIå¯è§æ€§"""
        self.hide_ui = not self.hide_ui

        if self.hide_ui:
            # éšè—UIå…ƒç´ 
            self.title_bar.hide()
            self.control_group.hide()
            self.volume_label.hide()
            self.status_label.hide()
            self.separator.hide()
            self.language_label.hide()
            # è°ƒæ•´çª—å£å¤§å°
            self.resize(self.width(), 150)
            # è°ƒæ•´è¾¹è·
            self.central_widget.layout().setContentsMargins(10, 10, 10, 10)
        else:
            # æ˜¾ç¤ºUIå…ƒç´ 
            self.title_bar.show()
            self.control_group.show()
            self.volume_label.show()
            self.status_label.show()
            self.separator.show()
            self.language_label.show()
            # æ¢å¤çª—å£å¤§å°
            self.resize(self.width(), 300)
            # æ¢å¤è¾¹è·
            self.central_widget.layout().setContentsMargins(15, 15, 15, 15)

    def set_background_opacity(self, opacity):
        """è®¾ç½®èƒŒæ™¯é€æ˜åº¦"""
        self.background_opacity = int(opacity * 2.55)
        self.bg_color.setAlpha(self.background_opacity)
        self.update_background_style()

    def set_text_opacity(self, opacity):
        """è®¾ç½®æ–‡å­—é€æ˜åº¦"""
        self.text_opacity = int(opacity * 2.55)
        self.original_color.setAlpha(self.text_opacity)
        self.translation_color.setAlpha(self.text_opacity)
        self.update_text_style()

    def set_font_size(self, size):
        """è®¾ç½®å­—ä½“å¤§å°"""
        self.font_size = size
        self.apply_fonts()

    def set_model(self, model_name):
        """è®¾ç½®AIæ¨¡å‹"""
        self.model_name = model_name
        # é‡å¯ç¿»è¯‘çº¿ç¨‹
        if self.translation_worker:
            self.translation_worker.stop()
            self.translation_worker.wait(2000)
        self._start_translation_worker()
        print(f"åˆ‡æ¢æ¨¡å‹: {model_name}")

    def add_custom_model(self):
        """æ·»åŠ è‡ªå®šä¹‰æ¨¡å‹"""
        model_name, ok = QInputDialog.getText(self, "æ·»åŠ æ¨¡å‹", "è¯·è¾“å…¥æ¨¡å‹åç§°:")
        if ok and model_name.strip():
            if model_name not in self.custom_models:
                self.custom_models.append(model_name)
                print(f"æ·»åŠ æ¨¡å‹: {model_name}")
            else:
                QMessageBox.warning(self, "æç¤º", "è¯¥æ¨¡å‹å·²å­˜åœ¨!")

    def remove_current_model(self):
        """åˆ é™¤å½“å‰æ¨¡å‹"""
        if len(self.custom_models) <= 1:
            QMessageBox.warning(self, "æç¤º", "è‡³å°‘éœ€è¦ä¿ç•™ä¸€ä¸ªæ¨¡å‹!")
            return

        reply = QMessageBox.question(self, "ç¡®è®¤åˆ é™¤",
                                     f"ç¡®å®šè¦åˆ é™¤æ¨¡å‹ '{self.model_name}' å—?",
                                     QMessageBox.Yes | QMessageBox.No)

        if reply == QMessageBox.Yes:
            self.custom_models.remove(self.model_name)
            # åˆ‡æ¢åˆ°ç¬¬ä¸€ä¸ªæ¨¡å‹
            self.set_model(self.custom_models[0])
            print(f"åˆ é™¤æ¨¡å‹: {self.model_name}")

    def show_color_settings(self):
        """æ˜¾ç¤ºé¢œè‰²è®¾ç½®å¯¹è¯æ¡†"""
        bg_color = QColorDialog.getColor(self.bg_color, self, "é€‰æ‹©èƒŒæ™¯é¢œè‰²")
        if bg_color.isValid():
            self.bg_color = bg_color
            self.bg_color.setAlpha(self.background_opacity)
            self.update_background_style()

        original_color = QColorDialog.getColor(self.original_color, self, "é€‰æ‹©åŸæ–‡é¢œè‰²")
        if original_color.isValid():
            self.original_color = original_color
            self.original_color.setAlpha(self.text_opacity)
            self.update_text_style()

        translation_color = QColorDialog.getColor(self.translation_color, self, "é€‰æ‹©ç¿»è¯‘é¢œè‰²")
        if translation_color.isValid():
            self.translation_color = translation_color
            self.translation_color.setAlpha(self.text_opacity)
            self.update_text_style()

    def contextMenuEvent(self, event):
        """å³é”®èœå•äº‹ä»¶"""
        context_menu = QMenu(self)

        # Whisperæ¨¡å‹é€‰æ‹©
        whisper_menu = context_menu.addMenu("Whisperæ¨¡å‹")
        model_sizes = [
            ("base (æ¨è)", "base"),
            ("small (å¿«é€Ÿ)", "small"),
            ("medium (é«˜ç²¾åº¦)", "medium")
        ]

        for name, size in model_sizes:
            action = whisper_menu.addAction(name)
            action.setCheckable(True)
            action.setChecked(size == self.whisper_model_size)
            action.triggered.connect(lambda checked, s=size: self.set_whisper_model(s))

        # é€æ˜åº¦è®¾ç½®èœå•
        opacity_menu = context_menu.addMenu("èƒŒæ™¯é€æ˜åº¦")
        current_bg_opacity = int(self.background_opacity / 2.55)  # è½¬æ¢ä¸ºç™¾åˆ†æ¯”
        for opacity in [100, 80, 60, 40, 20]:
            action = opacity_menu.addAction(f"{opacity}%")
            action.setCheckable(True)
            action.setChecked(opacity == current_bg_opacity)
            action.triggered.connect(lambda checked, o=opacity: self.set_background_opacity(o))

        text_opacity_menu = context_menu.addMenu("æ–‡å­—é€æ˜åº¦")
        current_text_opacity = int(self.text_opacity / 2.55)  # è½¬æ¢ä¸ºç™¾åˆ†æ¯”
        for opacity in [100, 80, 60, 40, 20]:
            action = text_opacity_menu.addAction(f"{opacity}%")
            action.setCheckable(True)
            action.setChecked(opacity == current_text_opacity)
            action.triggered.connect(lambda checked, o=opacity: self.set_text_opacity(o))

        font_menu = context_menu.addMenu("å­—ä½“å¤§å°")
        for size in [14, 16, 18, 20, 24]:
            action = font_menu.addAction(f"{size}px")
            action.triggered.connect(lambda checked, s=size: self.set_font_size(s))

        context_menu.addSeparator()

        # AIæ¨¡å‹é€‰æ‹©
        model_menu = context_menu.addMenu("AIæ¨¡å‹")

        # æ·»åŠ ç°æœ‰æ¨¡å‹
        for model in self.custom_models:
            action = model_menu.addAction(model)
            action.setCheckable(True)
            action.setChecked(model == self.model_name)
            action.triggered.connect(lambda checked, m=model: self.set_model(m))

        model_menu.addSeparator()

        # æ·»åŠ è‡ªå®šä¹‰æ¨¡å‹é€‰é¡¹
        add_model_action = model_menu.addAction("â• æ·»åŠ è‡ªå®šä¹‰æ¨¡å‹")
        add_model_action.triggered.connect(self.add_custom_model)

        remove_model_action = model_menu.addAction("ğŸ—‘ï¸ åˆ é™¤å½“å‰æ¨¡å‹")
        remove_model_action.triggered.connect(self.remove_current_model)

        # éšè—UIé€‰é¡¹
        hide_ui_action = context_menu.addAction("éšè—UIæ§ä»¶")
        hide_ui_action.setCheckable(True)
        hide_ui_action.setChecked(self.hide_ui)
        hide_ui_action.triggered.connect(self.toggle_ui_visibility)

        context_menu.addSeparator()

        color_action = context_menu.addAction("é¢œè‰²è®¾ç½®")
        color_action.triggered.connect(self.show_color_settings)

        context_menu.addSeparator()

        exit_action = context_menu.addAction("é€€å‡º")
        exit_action.triggered.connect(self.close)

        context_menu.exec_(event.globalPos())

    def mousePressEvent(self, event):
        """é¼ æ ‡æŒ‰ä¸‹äº‹ä»¶"""
        if event.button() == Qt.LeftButton:
            self.drag_start_position = event.globalPos() - self.frameGeometry().topLeft()
            event.accept()

    def mouseMoveEvent(self, event):
        """é¼ æ ‡ç§»åŠ¨äº‹ä»¶"""
        if event.buttons() == Qt.LeftButton and hasattr(self, 'drag_start_position'):
            self.move(event.globalPos() - self.drag_start_position)
            event.accept()

    def setup_keyboard_listener(self):
        """è®¾ç½®é”®ç›˜ç›‘å¬"""

        def on_press(key):
            try:
                if key == keyboard.Key.f2:
                    self.toggle_recording()
                elif key == keyboard.Key.esc:
                    self.close()
            except:
                pass

        self.keyboard_listener = keyboard.Listener(on_press=on_press)
        self.keyboard_listener.daemon = True
        self.keyboard_listener.start()

    def closeEvent(self, event):
        """ç¨‹åºå…³é—­äº‹ä»¶"""
        self.stop_recording()

        # åœæ­¢ç¿»è¯‘çº¿ç¨‹
        if self.translation_worker:
            self.translation_worker.stop()
            self.translation_worker.wait(3000)

        if hasattr(self, 'keyboard_listener'):
            self.keyboard_listener.stop()
        event.accept()


def main():
    app = QApplication(sys.argv)
    app.setStyle('Fusion')

    window = DraggableSubtitleWindow()
    window.show()

    print("=" * 60)
    print("ğŸ¯ åŒè¯­å­—å¹•å¯åŠ¨ - Whisperæ™ºèƒ½ç‰ˆæœ¬!")
    print("ğŸ“ æ‰§è¡Œé¡ºåº: Whisperè¯†åˆ« â†’ è‡ªåŠ¨è¯­è¨€æ£€æµ‹ â†’ æ™ºèƒ½ç¿»è¯‘ â†’ æ˜¾ç¤ºè¯‘æ–‡")
    print("ğŸŒ è¯­éŸ³è¯†åˆ«: å®Œå…¨ç¦»çº¿ | è‡ªåŠ¨æ£€æµ‹ä¸­è‹±æ–‡ | ç¿»è¯‘: éœ€è¦Ollama")
    print("ğŸ¹ å¿«æ·é”®: F2å¼€å§‹/åœæ­¢ç¿»è¯‘ | ESCé€€å‡ºç¨‹åº")
    print("=" * 60)

    sys.exit(app.exec_())


if __name__ == "__main__":
    main()
